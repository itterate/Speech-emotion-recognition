# Speech-emotion-recognition

# Abstract

Speech emotion recognition is the perspective field of study that can be helpful in various industries. For example, it can used for digital avatars where the AI can determine the tone and emotions of the userâ€™s voice for further generation messages. The study explores speech emotion recognition using CNN (1-dimensional Convolutional Neural Network) and Facebook transformer which pre-trained from 960 hours of audio. As a main dataset, CREMA-D was used in the project containing about 7200 samples where several voice actors repeated phrases with different intonations, the target values are happy, sad, fear, neutral, anger, and disgust. To extract information from wav type audio file, I used librosa library and implemented data augmentation in the training dataset by adding noise, fetching, and stretching the audio. The data was sliced into training, validation, and test data with the ratio 7:1,5:1,5 respectively. For fine-tuning the best hyperparameters for CNN optuna were implemented and the results get 3 layers with 256, 128, and 64 filter numbers for each layer. Overall, the transformer model outperformed the CNN model with an accuracy score of 60% and 40% respectively.
